{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a8832c-9d5a-4b30-b06b-b45c09770201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 1. Load and Preprocess Data\n",
    "# Assume you have a CSV file with columns: 'Artist', 'Song Title', 'Release Year', 'Genre', 'Lyrics', 'Topic', 'Interested'\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"lyrics_data_music.csv\")\n",
    "\n",
    "# Drop rows with any missing values in the important columns\n",
    "df = df.dropna(subset=['Artist', 'Song Title', 'Release Year', 'Genre', 'Lyrics', 'Topic'])\n",
    "\n",
    "# Remove stopwords from lyrics\n",
    "df['Lyrics'] = df['Lyrics'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "df['Interested'] = df['Genre'].apply(lambda x: 'Yes' if x in ['pop', 'blues'] else 'No')\n",
    "# 2. Split Data\n",
    "X = df['Lyrics']\n",
    "y = df['Interested']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c3ce86-9f55-4fb6-8bf1-ab700de99ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f68b533-5a62-4ed9-b3fd-1aa79f5e9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=0.0, max_df=1.0, max_features=1000, lowercase=True)\n",
    "vectorizer.fit(x_train)\n",
    "x_train = vectorizer.transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8899951d-ba48-4390-81f6-01235bddcd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.astype('float32')\n",
    "y_train = y_train.replace({'No': 0, 'Yes': 1}).astype('float32')\n",
    "X_test = x_test.astype('float32')\n",
    "y_test = y_test.replace({'No': 0, 'Yes': 1}).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd1c8a1-12c9-42cd-a7b5-0b5f8860ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df674e6-1b41-49ce-b705-bedaaeb611cb",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858c74f-83b1-419b-b391-bed658ea3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier_rbf=SVC (kernel='rbf',random_state=0)\n",
    "classifier_rbf.fit(X_train,y_train)\n",
    "y_pred_bf=classifier_rbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30630470-ff33-4183-bb6c-ec27463583b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_rbf=confusion_matrix(y_test,y_pred_bf)\n",
    "print(cm_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ccda00-4da7-4956-8422-22844c4cb29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report_rbf=classification_report(y_test,y_pred_bf)\n",
    "print(class_report_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df99d11-160f-4e84-8c93-9f7b60d533b8",
   "metadata": {},
   "source": [
    "### Random_Forest_Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef5cc0-e358-4ccd-aa46-39b852e52495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model=RandomForestRegressor(n_estimators=10,random_state=0)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e631962-fd59-42f0-9c4e-e28494270086",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4884d46-f18c-443b-a359-954c05ba9ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert continuous predictions to binary or discrete classes, e.g., using rounding\n",
    "y_pred_class = np.round(y_pred).astype(int)  \n",
    "# Generate the classification report\n",
    "class_report_RFR = classification_report(y_test, y_pred_class)\n",
    "print(class_report_RFR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f990b2b1-b236-4397-bd4a-a10d2f531f16",
   "metadata": {},
   "source": [
    "### Navie_Bayes_Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1689ec6-301f-4323-9872-27fe3e82a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c4541-5cda-40f9-9ece-5751da89c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrices to dense\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "# Initialize and fit the model\n",
    "nb1 = GaussianNB()\n",
    "nbg_pred=nb1.fit(X_train_dense, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a02ae-9210-4833-a12c-d1c3dc24577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "nbg_pred = nb1.predict(X_test_dense)\n",
    "\n",
    "# Now create the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "class_report_RFR = classification_report(y_test, nbg_pred)\n",
    "print(class_report_RFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c425fe8-8508-4ca3-939f-6cef0ab85076",
   "metadata": {},
   "source": [
    "### Linear_Regression_Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e4283f-ed57-4dc5-b34e-153649cbe26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#load the model\n",
    "lr= LinearRegression()\n",
    "#train the model on the training model\n",
    "lr.fit(X_train,y_train)\n",
    "#predicting the test data so that we can later evalute the model\n",
    "pred_lr=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb604daf-eb47-4208-a6ce-350950b11968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure pred_lr contains class labels, not probabilities\n",
    "pred_lr = model.predict(X_test)  # Replace 'model' with your trained model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb6155-f214-4bb4-b763-d08fac9a7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If pred_lr contains probabilities, convert to class labels\n",
    "pred_lr = (pred_lr >= 0.5).astype(int)  # Adjust threshold as needed for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584ce7c7-86c6-44eb-8114-deb722663a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report_lr = classification_report(y_test, pred_lr)\n",
    "print(class_report_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ca1ac-e5d4-45a2-aba2-c0dd10d2ee70",
   "metadata": {},
   "source": [
    "### K-NN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae58107-482b-44ab-acf4-2341f9bca827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26f1e5-394d-40a3-8b68-2abb99495fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "pred_knn = model.predict(X_test)\n",
    "# Evaluate regression metrics\n",
    "mse = mean_squared_error(y_test, pred_knn)\n",
    "r2 = r2_score(y_test, pred_knn)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45a3ce-84ab-48e6-ab05-2ca2cf5da8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Instantiate and fit a classifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "pred_knn = model.predict(X_test)\n",
    "class_report = classification_report(y_test, pred_knn)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54226554-b846-42ec-bf44-012504fba7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot for actual vs predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, pred_knn, color='blue', alpha=0.6, edgecolor='k')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', linewidth=2)  # Line y=x\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c2ffd-1ead-49a6-bff6-687574496bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - pred_knn\n",
    "\n",
    "# Plot the distribution of residuals\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(residuals, kde=True, color=\"purple\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Error Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f11716-7664-41dc-99ee-607c6548968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, pred_knn)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=model.classes_)\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa1e1d-66d9-41f4-9da3-4828244f9dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Calculate regression metrics\n",
    "mae = mean_absolute_error(y_test, pred_y)\n",
    "mse = mean_squared_error(y_test, pred_y)\n",
    "r2 = r2_score(y_test, pred_y)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"RÂ² Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724013e-599a-4698-a7f8-f06df06240bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2ccf6cb-29f4-446f-a178-8ff8594f0a4a",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b1562-d35c-43c9-ab2f-b5d8501ac40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming song_data is your DataFrame\n",
    "# Here, X represents the feature columns, and y is the target variable, for example, 'Romantic'\n",
    "\n",
    "# Define features and target\n",
    "X = df['Lyrics']\n",
    "y = df['Interested']\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Check the results\n",
    "print(\"Training set size:\", len(x_train))\n",
    "print(\"Test set size:\", len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bad22f-a96e-4e13-ba49-e36153027509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df = 0.0, max_df = 1.0, max_features = 1000,lowercase = True)\n",
    "vectorizer.fit(x_train)\n",
    "vectorizer.fit(x_test)\n",
    "X_train = vectorizer.transform(x_train)\n",
    "X_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363f01a-3fda-4198-b2e4-ae5b056a5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Set up the NN\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import models\n",
    "input_dimension = X_train.shape[1]\n",
    "print(input_dimension)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(16, input_dim = input_dimension, activation = 'relu'))\n",
    "model.add(layers.Dense(16, activation = 'relu'))\n",
    "model.add(layers.Dense(16, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f53080a-577e-4b14-a866-f618fed49bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "optimizer = 'adam',\n",
    "metrics = ['accuracy'])\n",
    "# summarize the model to make sure that it's structured as intended\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088eec56-55cd-44a1-a52a-666e95dc6ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.replace({'No': 0, 'Yes': 1}).astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.replace({'No': 0, 'Yes': 1}).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855aed90-cdd8-4994-9271-b626bfe65970",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "epochs=30,\n",
    "verbose=True,\n",
    "validation_data=(X_test, y_test),\n",
    "batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f08b6-0181-4026-85b7-8a0e19cbe458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad932e-671a-44b6-8018-f02a8fb61a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a2a632-18ee-4db5-bfff-7fa07f311db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ebd5b-77ef-403a-acc8-2a970f2ebe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f1084-8e69-4c65-9c69-b0e62a3e75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(x, val_acc, 'r', label = 'Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend(fontsize = 14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    #plt.savefig('acc.svg')\n",
    "    #plt.show()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend(fontsize = 14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.savefig('loss.svg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d134b69f-12e8-4574-a403-331c5131e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700420d-a2b7-45f8-b460-269e15b4b356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102fc924-9391-495e-9567-4d756e8814af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae850358-87e0-484e-9925-a61503c46d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce2c3de-fe53-439b-8e18-7d23879d9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Set up the NN\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "input_dimension = X_train.shape[1]\n",
    "print(input_dimension)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(32, input_dim = input_dimension, activation = 'swish'))\n",
    "\n",
    "model.add(layers.Dense(32, activation = 'swish'))\n",
    "model.add(layers.Dense(32, activation = 'swish'))\n",
    "\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b2452-b536-426b-8fb3-06cc75a5a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "optimizer = 'adam',\n",
    "metrics = ['accuracy'])\n",
    "# summarize the model to make sure that it's structured as intended\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda2e95-e513-4212-a2e2-08ce48d47065",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "epochs=20,\n",
    "verbose=True,\n",
    "validation_data=(X_test, y_test),\n",
    "batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba856914-e0da-455a-ae31-909673ba4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69010fb6-2533-4b6d-a10e-11e528d0c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28f3c1-beb7-4cef-81bd-9e4273a7de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(x, val_acc, 'r', label = 'Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend(fontsize = 14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    #plt.savefig('acc.svg')\n",
    "    #plt.show()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend(fontsize = 14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.savefig('loss.svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0c65e-98b5-4267-b7f3-d964260e0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da4181-543b-419b-8e50-114603d2da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1befc067-5830-4267-8d32-92b46fdbbc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c2a914-8ba3-4baf-b4e6-e0d92401326c",
   "metadata": {},
   "source": [
    "### BERT Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32dcba9-e27b-49f6-a188-28517da871ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Assuming 'selected_rows' is your DataFrame and 'Cleaned_Lyrics' and 'Interested' are columns\n",
    "X = df['Lyrics'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "y = df['Interested'].replace({'No': 0, 'Yes': 1})  # Convert labels to binary\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the text\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Define a custom dataset class for binary classification\n",
    "class BinaryClassificationDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create the train and test datasets\n",
    "train_dataset = BinaryClassificationDataset(train_encodings, train_labels)\n",
    "test_dataset = BinaryClassificationDataset(test_encodings, test_labels)\n",
    "\n",
    "# Load the pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5576a48d-92aa-4bdf-8ad3-6ec76d5a57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=5,\n",
    "    eval_strategy=\"epoch\",  # Use eval_strategy instead of evaluation_strategy\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=[\"none\"]\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained('./fine_tuned_bert')\n",
    "tokenizer.save_pretrained('./fine_tuned_bert')\n",
    "\n",
    "# Evaluate the model and print the classification report\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "print(classification_report(test_labels, preds))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
